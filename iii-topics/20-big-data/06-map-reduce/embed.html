<!doctype html><html lang=en-us dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.148.1"><meta name=generator content="Relearn 8.0.0"><meta name=description content="Resources Slides Video Script One of the last things I want to talk about here with big data is some of the algorithms that we can actually use to work with this sheer amount of information. So one that I want to highlight here is called MapReduce. Oh, MapReduce is a very well known algorithm and big data realm. And now it’s been, of course, transformed significantly, since its original inception, inception, to handle even larger amounts of information. But the idea here is that we take a very large amount of information, let’s say text, and then we map it to smaller parts, break it out, and then we recombine that and to produce a final result. Okay. And so if you can use this as an example, right, if we’re trying to, let’s say, sort of deck of cards, okay, if I asked if I give you a whole bunch, or if I give you a full deck of cards that is completely shuffled, but I want you to sort it out in numerical order, as well as the suits would actually take you a little bit of time to actually achieve that task. But if I were allow it, if I gave you a deck of cards in a group, well, so let’s say I gave a group of 10 people, one single deck of cards, and I said, sort do the same thing, it will take them significantly less time than it will if I gave just one person a deck of cards to actually achieve that end result."><meta name=author content="K-State CS Faculty"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://textbooks.cs.ksu.edu/cs-zero/images/hero.png"><meta name=twitter:title content="Map Reduce :: Intro CS Textbook"><meta name=twitter:description content="Resources Slides Video Script One of the last things I want to talk about here with big data is some of the algorithms that we can actually use to work with this sheer amount of information. So one that I want to highlight here is called MapReduce. Oh, MapReduce is a very well known algorithm and big data realm. And now it’s been, of course, transformed significantly, since its original inception, inception, to handle even larger amounts of information. But the idea here is that we take a very large amount of information, let’s say text, and then we map it to smaller parts, break it out, and then we recombine that and to produce a final result. Okay. And so if you can use this as an example, right, if we’re trying to, let’s say, sort of deck of cards, okay, if I asked if I give you a whole bunch, or if I give you a full deck of cards that is completely shuffled, but I want you to sort it out in numerical order, as well as the suits would actually take you a little bit of time to actually achieve that task. But if I were allow it, if I gave you a deck of cards in a group, well, so let’s say I gave a group of 10 people, one single deck of cards, and I said, sort do the same thing, it will take them significantly less time than it will if I gave just one person a deck of cards to actually achieve that end result."><meta property="og:url" content="https://textbooks.cs.ksu.edu/cs-zero/iii-topics/20-big-data/06-map-reduce/index.html"><meta property="og:site_name" content="Intro CS Textbook"><meta property="og:title" content="Map Reduce :: Intro CS Textbook"><meta property="og:description" content="Resources Slides Video Script One of the last things I want to talk about here with big data is some of the algorithms that we can actually use to work with this sheer amount of information. So one that I want to highlight here is called MapReduce. Oh, MapReduce is a very well known algorithm and big data realm. And now it’s been, of course, transformed significantly, since its original inception, inception, to handle even larger amounts of information. But the idea here is that we take a very large amount of information, let’s say text, and then we map it to smaller parts, break it out, and then we recombine that and to produce a final result. Okay. And so if you can use this as an example, right, if we’re trying to, let’s say, sort of deck of cards, okay, if I asked if I give you a whole bunch, or if I give you a full deck of cards that is completely shuffled, but I want you to sort it out in numerical order, as well as the suits would actually take you a little bit of time to actually achieve that task. But if I were allow it, if I gave you a deck of cards in a group, well, so let’s say I gave a group of 10 people, one single deck of cards, and I said, sort do the same thing, it will take them significantly less time than it will if I gave just one person a deck of cards to actually achieve that end result."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="CS Topics"><meta property="article:published_time" content="2020-10-24T00:27:26-05:00"><meta property="article:modified_time" content="2025-12-05T14:20:44-06:00"><meta property="og:image" content="https://textbooks.cs.ksu.edu/cs-zero/images/hero.png"><meta itemprop=name content="Map Reduce :: Intro CS Textbook"><meta itemprop=description content="Resources Slides Video Script One of the last things I want to talk about here with big data is some of the algorithms that we can actually use to work with this sheer amount of information. So one that I want to highlight here is called MapReduce. Oh, MapReduce is a very well known algorithm and big data realm. And now it’s been, of course, transformed significantly, since its original inception, inception, to handle even larger amounts of information. But the idea here is that we take a very large amount of information, let’s say text, and then we map it to smaller parts, break it out, and then we recombine that and to produce a final result. Okay. And so if you can use this as an example, right, if we’re trying to, let’s say, sort of deck of cards, okay, if I asked if I give you a whole bunch, or if I give you a full deck of cards that is completely shuffled, but I want you to sort it out in numerical order, as well as the suits would actually take you a little bit of time to actually achieve that task. But if I were allow it, if I gave you a deck of cards in a group, well, so let’s say I gave a group of 10 people, one single deck of cards, and I said, sort do the same thing, it will take them significantly less time than it will if I gave just one person a deck of cards to actually achieve that end result."><meta itemprop=datePublished content="2020-10-24T00:27:26-05:00"><meta itemprop=dateModified content="2025-12-05T14:20:44-06:00"><meta itemprop=wordCount content="943"><meta itemprop=image content="https://textbooks.cs.ksu.edu/cs-zero/images/hero.png"><title>Map Reduce :: Intro CS Textbook</title><link href=https://textbooks.cs.ksu.edu/cs-zero/iii-topics/20-big-data/06-map-reduce/index.html rel=canonical type=text/html title="Map Reduce :: Intro CS Textbook"><link href=/cs-zero/iii-topics/20-big-data/06-map-reduce/index.xml rel=alternate type=application/rss+xml title="Map Reduce :: Intro CS Textbook"><link href=/cs-zero/iii-topics/20-big-data/06-map-reduce/index.print.html rel=alternate type=text/html title="Map Reduce :: Intro CS Textbook"><link href=/cs-zero/iii-topics/20-big-data/06-map-reduce/tele.html rel=alternate type=text/html title="Map Reduce :: Intro CS Textbook"><link href=/cs-zero/css/auto-complete/auto-complete.min.css?1767801774 rel=stylesheet><script src=/cs-zero/js/auto-complete/auto-complete.min.js?1767801774 defer></script><script src=/cs-zero/js/search-lunr.min.js?1767801774 defer></script><script src=/cs-zero/js/search.min.js?1767801774 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/cs-zero/searchindex.en.js?1767801774"</script><script src=/cs-zero/js/lunr/lunr.min.js?1767801774 defer></script><script src=/cs-zero/js/lunr/lunr.stemmer.support.min.js?1767801774 defer></script><script src=/cs-zero/js/lunr/lunr.multi.min.js?1767801774 defer></script><script src=/cs-zero/js/lunr/lunr.en.min.js?1767801774 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/cs-zero/fonts/fontawesome/css/fontawesome-all.min.css?1767801774 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/cs-zero/fonts/fontawesome/css/fontawesome-all.min.css?1767801774 rel=stylesheet></noscript><link href=/cs-zero/css/perfect-scrollbar/perfect-scrollbar.min.css?1767801774 rel=stylesheet><link href=/cs-zero/css/theme.min.css?1767801774 rel=stylesheet><link href=/cs-zero/css/format-html.min.css?1767801774 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/iii-topics/20-big-data/06-map-reduce/index.html",window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../../..",window.relearn.absBaseUri="https://textbooks.cs.ksu.edu/cs-zero",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!0,window.relearn.enableBlockCodeWrap=!1,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.relearn.themevariants=["light-theme"],window.relearn.customvariantname="my-custom-variant",window.relearn.writeVariant=!1,window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.writeVariant&&window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script><link href=/cs-zero/css/custom.css?1767801774 rel=stylesheet></head><body class="mobile-support embed html" data-url=/cs-zero/iii-topics/20-big-data/06-map-reduce/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><div id=R-main-overlay></div><main id=R-body-inner class="highlightable iii-topics" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=map-reduce>Map Reduce</h1><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/bivx7Ic2SFA style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h4 id=resources>Resources</h4><ul><li><a href=/cs-zero/slides/20-BigData.pdf>Slides</a></li></ul><h4 id=video-script>Video Script</h4><p>One of the last things I want to talk about here with big data is some of the algorithms that we can actually use to work with this sheer amount of information. So one that I want to highlight here is called MapReduce. Oh, MapReduce is a very well known algorithm and big data realm. And now it&rsquo;s been, of course, transformed significantly, since its original inception, inception, to handle even larger amounts of information. But the idea here is that we take a very large amount of information, let&rsquo;s say text, and then we map it to smaller parts, break it out, and then we recombine that and to produce a final result. Okay. And so if you can use this as an example, right, if we&rsquo;re trying to, let&rsquo;s say, sort of deck of cards, okay, if I asked if I give you a whole bunch, or if I give you a full deck of cards that is completely shuffled, but I want you to sort it out in numerical order, as well as the suits would actually take you a little bit of time to actually achieve that task. But if I were allow it, if I gave you a deck of cards in a group, well, so let&rsquo;s say I gave a group of 10 people, one single deck of cards, and I said, sort do the same thing, it will take them significantly less time than it will if I gave just one person a deck of cards to actually achieve that end result.</p><p>So that&rsquo;s the idea of MapReduce, we partition our information out into very small parts. And then each of those small parts has the same task done to it. And once that task has been executed on the small parts, all of the end results are then combined to produce the final results. So let&rsquo;s take a look at another example here with word count, which is pretty a real classic example of how MapReduce works. So our input here is a very simple section of texts. So a bunch of different words, dear bear, river, car, car, river, deer car bear. And so you can imagine this being a very large book or something like that. And we want to count the count the occurrences of each word in our in our data set. So first thing that we do here, let&rsquo;s split this data out. So let&rsquo;s say that each line of text here is our initial split. So deer, bear, river, car, car, river, and deer car bear. So we have these three, these three data sets that are that are our big data set has been split into these individual data sets. Where each the key value we have key value pair, where the key is this as a document, the value is the the text that we actually contain. So each of these documents here are then going to be mapped to a task. And our task here is to count the word occurrences.</p><p>So in this mapping task, I&rsquo;m going to map each word to a number. So each word of course, and individualized is only going to occur once. So deer occurs once bear occurs once and river occurs once. The key here is going to be word and the value here is going to be of course, the word count. As you can see down here in this middle example, where we have two cars, that&rsquo;s okay, because it&rsquo;s individual tasks, remember, so each car is still going to be one key value pair here. Because the important part actually comes in the next step. And the next few steps here. So we&rsquo;re actually going to shuffle this out on the shuffling process is going to take care of essentially sorting the result of our mapping process. Because once it&rsquo;s actually sorted, it&rsquo;s a lot easier to easier to actually reduce and combine. So when we actually shuffle all of the bears and get put in one bin, all the cars get put in one bin, all the deer get put in one bin and all of the rivers get put in one bin.</p><p>And then all that happens here is actually the reducing so we actually combining one more step actually combining the information. So we sum the word counts. So bear occurred twice, car three, deer two and river two. So we&rsquo;ve taken all of the individual words here, counted them and sorted them out and summed them. And then the final reduce phase is we&rsquo;ve combined this all back into a single list, where the key is the word and the value is the total word count over the entire day. To set. But you can imagine this to be significantly faster than having a one single process or one single out or one single computer doing this, we can use this on things like Beocat, a distributed computer system where we can throw a split the data set up and onto a lot of different processors and have each processor each thread actually execute the mapping, shuffling and reducing task. And then they all come in back together at the end to form the final results. But this is just one of the big data algorithms out there. There&rsquo;s obviously a significant amount of other types of techniques and algorithms and tasks out there, that big data can actually accomplish. So we&rsquo;ve just scratched the surface here. But if you&rsquo;re interested in learning more, please reach out and we happy to actually connect to you with more resources.</p><footer class=footline></footer></article></div></main></div><script src=/cs-zero/js/clipboard/clipboard.min.js?1767801774 defer></script><script src=/cs-zero/js/perfect-scrollbar/perfect-scrollbar.min.js?1767801774 defer></script><script src=/cs-zero/js/theme.min.js?1767801774 defer></script><script src=/cs-zero/js/embed-iframe.min.js?1767801774 defer></script></body></html>